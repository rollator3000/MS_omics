NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES

----- INTRO ------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
1. Slide ----- ----- ----- ----- -----
	- Herzlich wilkommen zu der Abschlusspräsentation meiner Masterarbeit.
	- Die Arbeit wurde von Dr. Hornung betreut und trägt den Titel:
		'A comparison study of predicition approaches for multiple training data sets & test data with block-wise missing values'

2. Slide ----- ----- ----- ----- -----
	>> Zuerst schauen wir uns kurz die Struktur der Präsentation an
 
		[1]	- Zu Beginn wird kurz erklärt, was 'block-wise missingness' ist

		[2] - Anschließend kommen wir zu dem Methoden-Teil. 
		    - Zuerst wird kurz das 'RandomForestModel' erklärt & anschließend die darauf 
		      basierenden Ansätze, um mit 'block-weise fehlden Daten' umzugehen: 
		      		> Der Complete-Case,
		      			  Single-Block,
		      			  Imputation,
		      			  Block-Wise & 
		      			  Fold-Wise Approach!

		[3] - Im Teil 'Benchmark Experiment' werden die Metriken, Datensätze & Techniken vorgestellt, um die Güte
		      der verschiedenen Ansätze zu evaluieren

		[4] - Im nächsten Kapitel werden dann die Ergebnisse dieser Benchmark-Experimente vorgestellt

		[5] - Zum Schluss werden die Ergebnisse diskutiert, es wird ein Fazit gezogen &
		      Vorschläge für die weitere Forschung in diesem Themen-Gebiet gemacht

[1. + 2. --> 0:55 - 1:00] 
----- Block-wise Missingness -------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
3. Slide ----- ----- ----- ----- -----
	>> Kommen wir zu dem Begriff 'Block-Wise Missingness'

	- BWM ist ein spezieller Fall von fehlenden Daten, der besonders im Context von Multi-Omics Daten häufig auftritt.

	- Die Tabelle zeigt ein Beispiel für einen Datensatz mit block-weise fehlenden Daten:
	  	- Insgesamt hat der Datensatz 105 Variablen und 8 Beobachtungen
	  		- Die Variablen 'weight', 'height', 'income' & 'education' sind ziemlich selbsterklärend,
	  		- 'g1', ..., 'g100' stehen für omics daten & 
	  		- 'Y' ist eine binäre response-variabel

	- Daten mit BWM bestehen immer aus unterschiedlichen >>Blocks<< und >>Folds<<
	  		
	  	- ein >>BLOCK<< beschreibt einfach ein set von variablen, die inhaltlich zusammen hängen
	  		- in unserm Beispiel gibt es 3 Blocks:
	  			- 'Block1' z.B. besteht aus den Variablen 'weight' & 'height'

		- ein >>FOLD<< beschreibt ein set von Observations, die in den gleichen Blöcken beobachtet wurden
			- in unserem Beispiel gibt es 3 Folds:
				- 'FOLD1' z.B. besteht nur aus den Beobachtungen, die in Block1 & Block2 beobachtet wurden
				  [also allen Beobachtungen, die in 'weight', 'height', 'income' & 'education' beobachtet wurden]
						
			- Die einzige Variable, die alle Observations gemeinsam haben müssen ist die response variabele 'Y'

	--> Daten mit BWM stellen ein Problem dar, da die meisten statistischen Methoden vollständig beobachtete Daten brauchen.
	   --> Im Verlauf der Präsentation werden verschiedene Ansätze vorgestellt, um mit solchen Block-Wise fehlenden Daten umzugehen

[3. --> ~1:20 - 1:30]
----- Methoden ---------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
4. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zum Methodenteil:

	- Zuerst wird das kurz RF-Model vorgestellt, da es die Grundlage für die nachkommenden Ansätze ist

	- Also: > Das RF-Model wurde 2001 von Leo Breimann vorgestellt & ist eine ensemble methode, die  
	          Entscheidungsbäume als base-learner benutzt. 
	        > Um diese Entscheidungsbäume zu trainieren, wird eine leicht veränderter Bagging Ansatz verwendet. 
	        	--> Dieser hat den Effekt, dass sich die einzelnen Entscheidungsbäume untereinander nicht zu ähnlich sind!
	        > Die Vorhersage eines RF entspricht dem durchschnitt/ der häugisten Ausprägung aller Vorhersagen der 
	          einzelnen Entscheidungsbäume
	        > Die 'predicitive-performance' eines RF-Models kann intern mit dem out-of-bag-Error geschätzt werden - 
	          dieser OOB-Error is fast identisch mit dem einer 'n-fold cross-validation'

[4. --> ~0:45 - 1:00]
5. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zum 1. Ansatz um mit block-wise fehlenden Daten umzugehen ---> Dem Complete-Case Approach!

	- Die Idee des Complete-Case Approaches ist es, dass die TrainingsDaten - in Bezug auf das Test-Set - so bearbeitet werden,
	  dass sie keine Block-wise fehlende Daten mehr beinhalten!

	- Die Methode wird nun anhand des unten stehenden Beispiels erklärt:
	  	> Man sieht ein Test-Set, das aus den Blöcken 'Clinical' und 'CNV' besteht
	  	> Darunter sind Trainingsdaten mit BWM dargestellt [bestehen aus insgesamt 4 blocks & 3 Folds]

	  	(1) Im ersten Schritt werden alle folds aus den Trainingsdaten entfernt, denen mind. ein Block aus dem Test-Set fehlt
	          >> in dem Beispiel, werden aus den Trainingsdaten die Folds 'Hospital 2' & 'Hospital 3' entfernt, da
	             diesen entweder der Block 'CNV' oder 'Clinical' fehlt

	    (2) Im nächsten Schritt werden dann alle Blöcke aus den TrainingsDaten entfernt, die nicht für die Test-Daten vorhanden sind.
	       	  >> in dem Beispiel werden sind das die Blöcke RNA & miRNA

	    	--> Auf dem resultierenden Datensatz (umrandet mit grüner Box) kann ein RF rergulär trainiert werden &
	      	    anschließend regulär Vorhersagen für das Test-Set treffen!

	- Der Complete-Case Approach hat 2 Nachteile:
		[1] Die Daten werden nicht besonders effizient genutzt!
		[2] Das 'Processing' der Trainings-Daten kann zu einem leeren Trainings-Daten führen! 
		    	--> In solchen Fällen sind keine Vorhersagen für das Test-Set möglich!

[5. --> ~ 1:20-1:30]
6. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zum 2. Ansatz um mit block-wise fehlenden Daten umzugehen - Dem Single-Block approach!

	- die Idee ist es, dass ein RF auf einem einzelnen Block [den Test- & Train gemeinsam haben] trainiert wird,
	  um dann Vorhersagen für das Test-Set zu treffen.

	  Die Methode wird wieder anhand des untenstehenden Beispiels erklärt.
	  	> Das Test-Set & die Trainingsdaten sind die gleichen wie in dem Beispiel davor

	  	(1) Im ersten Schritt werden alle Blöcke, die sich Test- & Train-Set teilen extrahiert & basierend darauf RFs trainiert.
	  		 >> In dem Beispiel haben die Train & Test-Daten die Blöcke 'Clinical' & 'CNV' gemeinsam.
	  		    Auf jedem dieser Blocks wird nun ein RF trainiert 
	  		    	--> insgesamt 2 RF Modelle [einmal basierend auf 'Clinical' & einmal basierend auf 'CNV']

	  	(2) Jedes dieser trainierten RFs kann dann Vorgersagen für das Test-Set liefern. 
		   	>> In dem Beispiel würde jede Beobachtung aus dem Test-Set zwei Vorhersage erhalten 
		   		- einmal basierend auf dem CNV Block &
		   		- einmal basierend auf dem Clinical Block.

	- Nachteil dieses Ansatzes ist es, dass die Daten nicht besonders effizient verwendet werden

[6. --> 0.55 - 1:05]

-------------------------------------------------------------------------------------------------------------------------------
7. Slide ----- ----- ----- ----- -----
	>> Der nächste Ansatz, um mit block-wise fehlenden Daten umzugehen ist der 'Imputation Approach'

	- die Idee ist es, die fehlenden Daten in dem Trainingsset zu imputieren, sodass dieser keine fehlenden Daten mehr enthält. 
	  Anahnd der imputierten Trainings-Daten kann dann ein RF gefittet werden, um anschließend Vorhersagen auf dem Test-Set treffen.

	  Die Methode wird anhand des untenstehenden Beispiels erklärt. 
	  	> Die Trainingsdaten sind die gleichen wie in den Beispielen davor & 
	  	  das Test-Set ist zusätzlich in dem Block 'miRNA' beobachtet.

	  	(1) Zuerst werden die fehlenden Daten mit der 'missForest'-Methode imputiert, sodass die Trainingsdaten dann 
	  	    komplett beobachtet sind und keine fehlenden Daten mehr enthalten

	  	(2) Auf den Blöcken, die das imputierte TrainingSet und das Test-Set gemeinsam haben, kann dann ein
	  	    RF regulär trainiert werden und anschließend Vorhersagen für das Test-Set generieren!

	Vorteil des Ansatzes:
		- Dieser Ansatz verwendet die Daten sehr effizient 

	Nachteil:
		- Der Nachteil des Ansatzes besteht in der Imputation selbst:
			- 1. Viele fehlende Daten in dem Train-Set führen zu unverlässlichen Imputationen
			- 2. Falls die Trainingsdaten von verschiedenen Quellen zusammengetragen wurde, macht das die 
		         Imputation unzuverlässig, weil die Datensätze heterogen sind!

[7. --> ~1:30]
8. Slide ----- ----- ----- ----- -----
	>> Der nächste Ansatz um mit block-wise fehlenden Daten umzugehen ist der Block-wise approach

	- Die idee ist es, dass auf jedem Block in den Trainingsdaten ein seperates RF Model gefittet wird. 
	  Für Vohersagen auf dem Test-Set werden dann die Vorhersagen dieser block-wise Models aggregiert.

	  Die Methode wird wieder anhand des unten stehenden Beispiels erklärt:
	  	> Die Trainings & Test-Daten sind die gleichen wie in dem vorherigen Beispiel

	  	(1) Zuerst werden die einzelnen Blöcke extrahiert, und auf deren beobachteten Teile wird 
	  	    jeweils ein RF Model traininert --> so viele RF Modelle wie Blöcke im Trainingsset
	  	    	>> In dem Beispiel hat man ein RF_clinical, RF_CNV, RF_rna & RF_miRNA

	  	(2) Im nächsten Scrhritt trifft jedes Modell Vorhersagen für das Test-Set
	  		--> nur die modelle, die auf einem Block trainiert wurden, der auch für das Test-Set vorhanden
	  		    ist, diese Vorhersage treffen!
	  		    >> In dem Beispiel können 3 der 4 Modelle Vorhersagen treffen. Einzig das Model 'RF_CNV' 
	  		       kann keine Vorhersage treffen, da das Test-Set nicht in dem Block 'CNV' beobachtet wurde!

	  	(3) Diese einzelnen Vorhersagen werden dann aggregiert für eine finale Vorhersage
				- Entweder nimmt man den reinen - also ungewichteten - Average ODER
				- man gewichteten die verschiedenen Block-Wise Models mit deren OOB Metric [Accuracy | F-1 Score]
				  	--> Deso besser die OOB-Metrik eines block-wise fitted models ist, 
				  	    desto höher das Gewicht diese block-wise predicitions

	- Dieser Ansatz verwendet die Daten sehr effizient und verwirft keine einzige Beobachtung/ Feature!

[8. --> ~1:40]
9. Slide ----- ----- ----- ----- -----
	>> Nun kommen wir zu dem letztem RF-Ansatz - dem Fold-Wise Approach

	- Die Idee des Ansatzes besteht darin, auf jedem Fold in den Trainingsdaten ein seperates Modell zu gefittet wird. 
	  Und für die Vorhersage auf einem Test-Set, werden die Vorhersagen der fold-wise models aggregiert.

	Dazu:	- Wird auf jedem Fold ein seperates RF-Model gefittet, sodass man so viele Modelle hat, wie die TrainingsDaten
	          Folds hat 	
	          	--> gezeigt in dem untenstehenden Beispiel: Pro Fold werden die beobachteten Blöcke genommen & der Response Y
	          	                                            und darauf basierend RFs trainiert!
	          	                                            	--> So viel fold-wise fitted models wie unique folds!

10. Slide ----- ----- ----- ----- -----
	--> Nur die Modelle, die auf einem Fold trainiert wurden, der mindestens einen Block mit dem Test-Set gemeinsam hat, 
	    können veruschen Vorhersagen zu treffen.
	    	--> dafür kann es aber sein, dass ein Modell geprunded werden muss.
                --> pruning wird in unserem Fall angewandt, wenn ein RF mindestens eine SplitVariable enthält,
                    die für eine Test-Beobachtung nicht vorhanden ist.

                    > der decision-tree links benutzt 'weight' & 'height' als split-variablen & hat 3 terminal nodes
						
					> Dieser decision-tree kann nicht angewandt werden, wenn die Beobachtung 'height' nicht hat.
						  	--> ABER wenn wir den decision-tree prunen, kann er Vorhersagen treffen für Beobachtungen ohne 'height'
						  	--> schneide den decision-tree zurecht, sodass jeder Node, der mit einer unbekannten Variable splitted
						  	    zu einem Terminal Node wird
						  	    --> Kann dann Vorhersagen treffen, auch wenn Test-Obs. gar nicht in 'height' beobachtet wurde

					> Wenn ein decision-tree an dem ersten Split gepruned werden muss, ist der decision-tree nicht mehr verwendbar 
					  & wird komplett von dem Entscheidugsbaum entfernt!

11. Slide ----- ----- ----- ----- ----
	>> Die Vorhersage für eine Test-Obs. entspricht dann dem gewichteten / ungewichteten Mittelwert der fold-wise RFs:
		Dazu: 
			- wird jedes Fold-wise fitted model nach einer Vorhersage gefragt.

				> RF(Hospital2) wurde auf den Blocks 'Clinical' & 'RNA' trainiert
					-> Vorhersage mit dem Modell auf den Tést-Daten regulär!


				> RF(Hospital1) & RF(Hospital3) wurden beide auf einem Fold mit 'CNV' trainiert
					--> CNV nicht vorhanden für Test-Set
						--> einzelnen Decision-Trees müssen gepruned werden, weil sie unter umständen
		    			   'CNV' features als SplitVariablen benutzen [nicht vorhanden für Test-Set]
		    			   	--> Nach dem Pruning kann das Modell dann Vorhersagen regulär treffen!

		    - diese fold-wise predicitons werden dann aggregiert zu einer finalen Vorhersage
				> unweighted: --> Mittelwert der fold-wise predicitions
				> weighted:   --> Benutze die OOB-Accuracy/ F-1-Score der gepruneden Fold-Wise Models als Gewicht, um 
				                  die einzelnen Vorhersagen zu gewichten

	- Dieser Ansatz verwendet die Daten sehr effizient und verwirft keine einzige Beobachtung/ Feature -  wie auch der BW approach!


------------------------------------------------------------------------------------------------------------------------
----- Benchmark Experiment ---------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
12. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zu dem Kapitel "Benchmark Experiments"
	
	>> Zuerst werden die METRIKEN vorgestellt!

	- Metriken werden verwendet, um zu bewerten, wie gut die Vorhersagen eines Modells mit den eigentlichen Daten übereinstimmen.

	- Da nur Datensätze mit binärem Response verwerndet wurden, werden nur Metriken für 'binäre Klassifikation' vorgestellt!
	  Alle Metriken sind - anders als z.B. die accuracy - insensibel zu Class Inbalaces in der response variable

	- Der 'F-1 Score' ist das harmonische Mittel aus der Precsion und Recall Metric [1. = precision || 2. = recall]

	- Die 'balanced accuracy' berechnet die Accuracy seperate pro Responseklasse und ist der Durchschnitt der class-wisen
	  accuracys!

	- Der 'Matthews Correlation Coefficent' ist die diskretisierung der pearson correlation für binäre Variable

	--> Für alle Metriken gitl, dass sie am besten sind mit dem Wert '1'
		Der 'F-1 Score' & die 'balanced accuracy' haben den schlechtesten Wert mit 0 & bei dem MCC bei -1

13. Slide ----- ----- ----- ----- -----
	>> Sprechn wir nun über die erste Quelle von Multi-Omics Daten --> 'The Cancer Genome Atlas' - kurz TCGA

	- Insgesamt wurden 21 Datensätze von meinem Betreuer zur Verfügung gestellt. 
	  Die Daten wurden bereits bearbeitet 	- die fehlenden Daten im Block 'Clincial' wurden imputiert!
	  										- kategoriale Variablen wurden in binäre numerische umgewandelt!
	  	--> 21 komplett Beobachtete Datensätze

	- Die Variable 'gender' aus dem Block 'Clinical' wurde als binäre response variable ausgewählt
		- Auch wenn das kein sinnvoller klinischer outcome ist, ist es für methodische Forschung in Ordnung diesen zu verwenden
			--> 7 der 21 DFs hatten keine Gender variable und wurden entfernt, sodass 14 DFs übrig blieben

	- Die 14 Datensätze haben alle die gleichen 5 Blöcke, wobei die Anzahl der Variablen in diese Blöcken reduziert wurde,
	  um den computionalen Aufwand zu reduzieren.
	  	--> Die Tabelle zeigt die durchschnittliche Anzahl an Variablen pro Block - einmal für die orginal daten &
	  	                                                                            einmal für die dimensions-reduizerten   

	  	    >> TABLE:	- clinical >> none
	  	     			- miRNA    >> 50%
	  	     			- Mutation >> 90%
	  	     			- CNV      >> 95%   
	  	     			- RNA      >> 85%

14. Slide ----- ----- ----- ----- -----
	>> Da alle 14 DFs komplett beobachtet sind, muss block-wise missingness induziert werden, für die benchmark experimente

	- Insgesamt gibt es vier verschiedene patterns:
		- Das erste zeigt den Fall, in dem die verschiedenen folds alle in einem einzelnen omics block & dem clinical block
		  beobachtet wurden
		- In dem zweiten Pattern ist der erste Fold in alle 5 Blocks beobachtet, der 2. Fold in nur 4 Blocks, der 3. Fold in 3 Blocks usw. 
		- In dem dritten Pattern wurden die beobachtetn Blöcke pro Fold zufällig gezogen
		- In dem letzten Pattern wurden 2 blocks zu einem einzelne vereint & jeder Fold ist in einem Omics-Block
		  und einem Clinical Block beobachtet!

15. Slide ----- ----- ----- ----- -----
	>> Sprechen wir nun kurz über den Algorithmus, um die Ansätze auf den TCGA Daten zu evaluieren

		- Zu Beginn wird ein Datensatz D, ein Approch APP und ein Block-wise missingness pattern PATT ausgewählt.
			> Der komplett beobachete Datensatz wird zuerste in  5 gleich große CV-folds eingeteilt
				> ein CV-Fold wird als Test-Set genommen & die restlichen vier als Train-Set
				> In das Train-Set wird dann die block-wise pattern PATT induziert
				> Der Approach wird dann auf verschiedenen Test-Sets evaluiert:
						- fully observed test-set
						- test-set mit einem fehlendem Feature-Block, and so on!

16. Slide ----- ----- ----- ----- -----
	>> Kommen wir jetzt zu zeiten Quelle für Mulit-Omics Daten - die 'clinical asthma data'

	- Die Daten sind von der Arbeitsgruppe von Prof. Dr. med. Bianca Schaub an der 
	  'pädiatrische Klinik Dr. von Haunersches Kinderspital'
	- Die Daten haben eine binäre response variable - asthma Yes/No 
		- from totally 521 observations: 265 have a negative \& 256 have a positive response
	- Die Daten bestehen aus 6 Blocks:
			- Questionaire, Clinical routine diagnostigs, allergen sensatzion, Cyoktine expression data, gene expression dáta 1&2
		    - Die Anzahl an Beobachtungen pro Block spiegelt umgekehrt den Aufwand zur Generierung der Daten wider
		    	>> weniger observations --> höherer Aufwand die Daten zu erheben

17. Slide ----- ----- ----- ----- -----
	>> Der Algorthmus zeigt den Ablauf um die Methoden auf den clinical asthma data zu evaluieren
		- 1. Zuerst wählt man einen approch
		- 2. Der DF wird dann in 5 gleich große CV-folds aufgeteilt
			- einer dieser CV-folds dient als test-fold & die restlichen als train-fold
			- dann werden die patterns of BWM in dem Test-Set extrahiert
			  [daten beinhalten schon BWM --> obs. in test-set sind auch in unterschiedlichen blocks beobachtet worden] 
				--> Für jedes pattern of BWM in the test-set, the approach generates predicitons
			--> Metrik für den momentanen CV-fold wird bestimmt, indem wahren klassen mit den vorhergesagten verglichen werden


------------------------------------------------------------------------------------------------------------------------
----- Results ----------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
18. Slide ----- ----- ----- ----- ----- 
	>> Kommen wir nun zu den Ergebnissen zu sprechen. Die Analyse der Ergebnisse fällt eher knapp aus, da sich die 
	   Präsentation sonst zu lange ziehen würde.
	   Es werden nur die besten Methoden miteinander verglichen.
	   	-> Für den SB-Approach steht in der Legende immer, welcher Block verwendet wurde
	   	-> Für den BW- & FW-Approach jeweils welche Gewichtung [OOB-Metrik] zu den besten Ergebnissen geführt hat


	 --> Der Plot zeigt die Ergebnisse der Ansätze für die verschiedenen Test-Situationen - x-Achse - und die y-Achse 
	     zeigt den etnsprechenden F-1 Score

	     - Sowohl der Fold-, als auch der Block-wise approach hatten ihre beste Perfromance mit dem 'F-1 Score' als OOB-Weight-Metric!
	     - Der Single-Block Approacjhhjuj

	     - Der Fold-Wise, Imputation & Block-Wise approach können in allen 20 test-Situations Vorhersagen treffen
	     - Der Single-Block approach nur in den Test-Situationen mit einem feature-block 'A' [9/20 Test-Situationen]
	     - Der Complete Case Approach kann nur in den Test-Situationen Vorhersagen treffen, in denen das Trainingset
	       'complete cases beinhaltet' [9/20 Testsituations der Fall]

	 --> Der Fold-Wise approach hat den besten median F-1Score in 11 test-situationen, der Imputation approach in 4 situationen
	     und der blockwise approach in 3 test-situationen
	     	--> CC & SB kein einziges das beste Ergebniss!


STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED 
STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED 

19. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Single-Block approach are shown.
	- For each pattern of BWM the results are shown split by the block that was used for the training of the SB-Approach
	- Two things are standing out:
		- Firstly: The SB approach can only generate predicitons for the test-sets that contain the block, that has been initially used for the training
		           (e.g. pattern4 - 'A' can only provide predicitons for test-sets with 'A')
		- Secondly: The performance of a single-block model is the same for the various test-situations. This makes 
		            sense, as the SB approach only uses a single block for the predicition & the various test-situations
		            only differ in the observed blocks, BUT not the blocks itself!


20. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Imputation approach are shown.
	- It stands out, that the imputation approach can provide predicitons for all possible test-situations!


21. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Block-Wise approach are shown.
	- To each test-situation, the results are shown structured by the weight used to aggregate the predicitions
	- It stands out, that the BW approach can provide predicitons for all possible test-situations!
	- Furthermore, it can be seen, that the weight_metric has no influence in the test-situations 'single_A'-'single_CL'
		--> this makes sense, as the test-set only consits of a single block 
		   --> no aggregation of BW predicitons!
	- Else it can be seen, that in all patterns and almost all test-situations the performance of the BW approach is the
	  best with the 'F-1 Score' as weight metric!


22. Slide ----- ----- ----- ----- -----
	- Last but not least the results of the FW approach are shown
	- As the BW & Imputation approach, this approach can provide predicitons for each test-situation
	- Furthermore, it can be seen, that the weight_metric has no influence in the test-situations in which only a single
	  fold from the training data can be used 
	  	- e.g. with 'Pattern 1' the performance in the test-situations 'single A', 'single B', 'single C' and
              'single D' is equal for the different weight metrics. 
              	--> That is reasonable, as in these test-situations only a single fold-wise fitted random forest model can
                    provide predictions, as the training-set only has a single fold that can be used for these test-situations.
					--> no aggregation of FW predicitons!

23. Slide ----- ----- ----- ----- -----

























ATTACHMENT
4. Slide ----- ----- ----- ----- -----
	>> Es gibt zwei Hauptgründe dafür, dass Block-Wise Missingness häufig im Kontext mit Multi-Omics Daten entsteht.

		>1< - Erstens, das erheben von 'omics Daten' ist deutlich teurer und komplexer ist, als es für normale 
		      klinische Daten. Darum können omics Daten meist -wg. monetären/ technischen Gründen - nicht für ALLE 
		      Teilnehmer einer Studie erhoben werden, sodass der Datensatz der Studie block-wise fehlende Daten enthält

		>2< - Der zweite ist, dass Datensätze von verschiedenen Quellen zusammengetragen werden. 
		 	- So ein Fall ist besipielhaft gezeigt in der untenstehenden Grafik. 
		 		- Zu sehen sind 3 verschiedene Datenquellen - von 3 verschiedenen Krankenhäusern, die alle Research im 
		 		  Bezug auf die Response-Variable 'Y' gemacht haben ('Asthma' - ja/nein?!)
				- Auch wenn die Krankehäuser für die gleiche Krankheit (Y) forschen, müssen sie nicht zwangsläufig die
				  gleichen Daten erheben
				- Wenn man diese zusammenfügt, entsteht Block-Wise missingness, weil die Beobachtungen aus den 
				  verschiedenen Krankenhäusern in verschieden Blocks beobachtet wurden
				  	--> Hospital1 hat nur die Blöcke 'CNV' & 'Clinical', sodass den Beobachtungen von dem Krankenhaus
				  	    nicht in den Blöcken 'RNA' & 'miRNA' beobachtet sind!