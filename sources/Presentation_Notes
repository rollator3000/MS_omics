NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES

----- INTRO ------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
1. Slide ----- ----- ----- ----- -----
	- Herzlich wilkommen zu der Abschlusspräsentation meiner Masterarbeit.
	- Die Arbeit wurde von Dr. Hornung betreut und trägt den Titel:
A comparison study of predicition approaches for multiple training data sets & test data with block-wise missing values

2. Slide ----- ----- ----- ----- -----
	>> Zuerst schauen wir uns kurz die Struktur der Präsentation an:
 
		[1]	- Zu Beginn wird kurz erklärt, was 'block-wise missingness' ist

		[2] - Anschließend kommen wir zu dem Methoden-Teil. 
		    - Hier wird zuerst kurz das 'RandomForestModel' erklärt & anschließend die darauf 
		      basierenden Ansätze, um mit 'block-weise fehlden Daten' umzugehen: 
		      		> Das ist der 	Complete-Case,
		      			  			Single-Block,
		      			  			Imputation,
		      			  			Block-Wise & 
		      			  			Fold-Wise Approach!

		[3] - Im Teil 'Benchmark Experiment' werden die Metriken, Datensätze & Techniken vorgestellt, um die Güte
		      der verschiedenen Ansätze zu evaluieren

		[4] - Im nächsten Kapitel werden dann die Ergebnisse dieser Benchmark-Experimente vorgestellt

		[5] - Zum Schluss werden die Ergebnisse diskutiert, es wird ein Fazit gezogen &
		      Vorschläge für die weitere Forschung in diesem Themen-Gebiet gemacht

[1. + 2. --> 0:50 - 1:00] 
----- Block-wise Missingness -------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
3. Slide ----- ----- ----- ----- -----
	>> Kommen wir zu dem Begriff 'Block-Wise Missingness'

	- BWM ist ein spezieller Fall von fehlenden Daten, der besonders häufig im Context von Multi-Omics Daten auftritt.

	- Die Tabelle zeigt ein Beispiel für einen Datensatz mit block-weise fehlenden Daten:
	  	- Insgesamt besteht der Datensatz aus 105 Variablen & 8 Beobachtungen
	  		- Die Variablen 'weight', 'height', 'income' & 'education' sind ziemlich selbsterklärend,
	  		- 'g1', ..., 'g100' stehen für omics daten & 
	  		- 'Y' ist eine binäre response-variabel

	- Daten mit BWM bestehen immer aus unterschiedlichen >>BLOCKS<< & >>FOLDS<<
	  		
	  	- ein >>BLOCK<< beschreibt einfach ein set von variablen, die inhaltlich zusammen hängen
	  		- in unserm Beispiel gibt es 3 Blocks!
	  			- 'BLOCK1' z.B. besteht aus den Variablen 'weight' & 'height'

		- ein >>FOLD<< beschreibt ein set von Observations, die in den gleichen Blöcken beobachtet wurden
			- in unserem Beispiel gibt es 3 Folds:
				- 'FOLD1' z.B. besteht aus den Beobachtungen, die in 'Block1' & 'Block2' beobachtet wurden
				  [also alle Beobachtungen, die in 'weight', 'height', 'income' & 'education' beobachtet wurden]
						
			- Die einzige Variable, die alle Observations gemeinsam haben müssen ist die response variabele 'Y'

	--> Daten mit BWM stellen ein Problem dar, da die meisten statistischen Methoden vollständig beobachtete Daten brauchen.

[3. --> ~1:15 - 1:25]
----- Methoden ---------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
4. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zum Methodenteil:

	- Hier wird zuerst kurz das kurz RF-Model vorgestellt, da es die Grundlage für die nachkommenden Ansätze ist

		> Das RF-Model wurde 2001 von Leo Breimann vorgestellt & ist eine ensemble methode, die Entscheidungsbäume als
		  base-learner benutzt. 
	    > Um diese Entscheidungsbäume zu trainieren, wird eine leicht veränderter Bagging Ansatz verwendet. 
	       	--> Dieser hat den Effekt, dass sich die einzelnen Entscheidungsbäume untereinander nicht zu ähnlich sind!
	    > Die Vorhersage eines RF entspricht dem durchschnitt aller Vorhersagen der einzelnen Entscheidungsbäume
	    > Die 'predicitive-performance' eines RF-Models kann intern mit dem out-of-bag-Error geschätzt werden - 
	      dabei ist diese OOB-estimation fast identisch mit der aus einer 'n-fold cross-validation'

[4. --> ~0:45 - 1:00]
5. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zum 1. Ansatz um mit block-wise fehlenden Daten umzugehen ---> Dem Complete-Case Approach!

	- Die Idee des Complete-Case Approaches ist es, dass die TrainingsDaten - in Bezug auf das Test-Set - so bearbeitet 
	  werden, dass sie keine Block-wise fehlende Daten mehr beinhalten!

	- Die Methode wird nun anhand des unten stehenden Beispiels erklärt:
	  	> Man sieht ein Test-Set, das aus den Blöcken 'Clinical' und 'CNV' besteht
	  	> Darunter sind Trainingsdaten mit BWM dargestellt - besteht aus insgesamt 4 blocks & 3 Folds

	  	(1) Im ersten Schritt werden alle Folds aus den Trainingsdaten entfernt, denen mind. ein Block aus dem Test-Set fehlt
	          >> in dem Beispiel, werden aus den Trainingsdaten die Folds 'Hospital 2' & 'Hospital 3' entfernt, da
	             diesen entweder der Block 'CNV' oder 'Clinical' fehlt

	    (2) Im nächsten Schritt werden dann alle Blöcke aus den TrainingsDaten entfernt, die nicht für die Test-Daten vorhanden sind.
	       	  >> in dem Beispiel sind das die Blöcke RNA & miRNA

	    	--> Auf dem resultierenden Datensatz (umrandet mit grüner Box) kann ein RF rergulär trainiert werden &
	      	    anschließend regulär Vorhersagen für das Test-Set treffen!

	- Der Complete-Case Approach hat 2 Nachteile:
		[1] Die Daten werden nicht besonders effizient genutzt!
		[2] Das 'Processing' der Trainings-Daten kann zu einem leeren Trainings-Daten führen! 
		    	--> In solchen Fällen sind keine Vorhersagen für das Test-Set möglich!

[5. --> ~ 1:20 - 1:30]
6. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zum 2. Ansatz um mit block-wise fehlenden Daten umzugehen - Dem Single-Block approach!

	- die Idee ist es, dass ein RF auf einem einzelnen Block [den Test- & Train gemeinsam haben] trainiert wird,
	  um dann Vorhersagen für das Test-Set zu treffen.

	  Die Methode wird wieder anhand des untenstehenden Beispiels erklärt.
	  	> Das Test-Set & die Trainingsdaten sind die gleichen wie in dem Beispiel davor

	  	(1) Im ersten Schritt werden alle Blöcke, die sich Test- & Train-Set teilen extrahiert & basierend darauf RFs trainiert.
	  		 >> In dem Beispiel haben die Train & Test-Daten die Blöcke 'Clinical' & 'CNV' gemeinsam.
	  		    Auf jedem dieser Blocks wird nun ein RF trainiert 
	  		    	--> insgesamt 2 RF Modelle [einmal basierend auf 'Clinical' & einmal auf 'CNV']

	  	(2) Jedes dieser trainierten RFs kann dann Vorgersagen für das Test-Set liefern. 
		   	>> In dem Beispiel würde jede Beobachtung aus dem Test-Set zwei Vorhersage erhalten 
		   		- einmal basierend auf dem CNV Block &
		   		- einmal basierend auf dem Clinical Block.

	- Nachteil dieses Ansatzes ist es, dass die Daten nicht besonders effizient verwendet werden

[6. --> 0.55 - 1:05]
7. Slide ----- ----- ----- ----- -----
	>> Der nächste Ansatz, um mit block-wise fehlenden Daten umzugehen ist der 'Imputation Approach'

	- die Idee ist es, die fehlenden Daten in dem Trainingsset zu imputieren, sodass die Trainingsdaten keine fehlenden 
	  Daten mehr enthalten. Anahnd dieser Daten kann dann ein RF gefittet werden, um anschließend Vorhersagen auf dem 
	  Test-Set zu treffen.

	  Die Methode wird anhand des untenstehenden Beispiels erklärt. 
	  	> Die Trainingsdaten sind die gleichen wie in den Beispielen davor & 
	  	  das Test-Set ist zusätzlich in dem Block 'miRNA' beobachtet.

	  	(1) Im ersten Schritt werden die fehlenden Daten mit der 'missForest'-Methode imputiert, sodass die Trainingsdaten
	  	    anschließend komplett beobachtet sind und keine fehlenden Daten mehr enthalten!

	  	(2) Im nächsten Schritt wird auf den Blöcken, die das imputierte TrainingSet und das Test-Set gemeinsam haben, 
	  	    ein RF trainiert und anschließend verwendet um Vorhersagen für das Test-Set generieren!
  	    		>> In dem Beispiel haben die imputiereten Trainingsdaten und das Test-Set die Blöcke 
  	    		   'CNV', 'Clinical' & 'miRNA' gemeinsam. Diese Blöcke werden aus den Trainingsdaten extrahiert
  	    		   und basierend darauf ein RF trainiert, das dann Vorhersagen für das Test-Set treffen kann

	- Dieser Ansatz verwendet die Daten sehr effizien. Der Nachteil des Ansatzes besteht in der Imputation selbst:
			- 1. Viele fehlende Daten in dem Train-Set führen zu unverlässlichen Imputationen
			- 2. Falls die Trainingsdaten von verschiedenen Quellen zusammengetragen wurde, macht das die 
		         Imputation unzuverlässig, weil die Datensätze heterogen sind!

[7. --> 1:15 - 1:25]
8. Slide ----- ----- ----- ----- -----
	>> Der nächste Ansatz um mit block-wise fehlenden Daten umzugehen ist der Block-wise approach

	- Die Idee ist es, dass auf jedem Block in den Trainingsdaten ein seperates RF Model gefittet wird. 
	  Für Vohersagen auf dem Test-Set werden dann die Vorhersagen dieser block-wise Models aggregiert.

	  Die Methode wird wieder anhand des unten stehenden Beispiels erklärt:
	  	> Die Trainings & Test-Daten sind die gleichen wie in dem vorherigen Beispiel

	  	(1) Zuerst werden die einzelnen Blöcke extrahiert, und auf deren beobachteten Teile wird 
	  	    jeweils ein RF Model traininert
	  	    	>> In dem Beispiel hat man 4 Modelle:	RF_clinical, RF_CNV, RF_rna & RF_miRNA

	  	(2) Im nächsten Schritt trifft jedes Modell Vorhersagen für das Test-Set! 
	  		--> nur die modelle, die auf einem Block trainiert wurden, der auch für das Test-Set vorhanden
	  		    ist, diese Vorhersage treffen!
	  		    >> In dem Beispiel können 3 der 4 Modelle Vorhersagen treffen. Einzig das Model 'RF_CNV' 
	  		       kann keine Vorhersage treffen, da das Test-Set nicht in dem Block 'CNV' beobachtet wurde!

	  	(3) Diese einzelnen 'block-wise' predicitions werden dann aggregiert für eine finale Vorhersage
	  			> unweighted: --> reinen Mittelwert der block-wise predicitions
				> weighted:   --> Benutze die OOB-Accuracy/ F-1-Score der Block-Wise Models als Gewicht, um 
				                  die einzelnen Vorhersagen zu gewichten

	- Dieser Ansatz verwendet die Daten sehr effizient und verwirft keine einzige Beobachtung/ Feature!

[8. --> ~1:40]
9. Slide ----- ----- ----- ----- -----
	>> Nun kommen wir zu dem letztem Ansatz um mit block-wise fehlenden Daten umzugehen - dem Fold-Wise Approach

	- Die Idee des Ansatzes besteht darin, auf jedem Fold in den Trainingsdaten ein seperates Modell zu fitten. 
	  Und für die Vorhersage auf einem Test-Set, werden die Vorhersagen der fold-wise models dann zu einer finalen 
	  prediciton aggregiert!

	  	(1) Im ersten Schritt wird auf jedem Fold in den Trainingsdaten ein seperates RF-Model gefittet!
	         >> dieser schritt ist in dem unteren Beispiel gezeigt: Pro Fold werden die beobachteten Blöcke genommen & 
	         	                                                    der Response Y und darauf basierend RFs trainiert!
	          	                                            			--> RF_Hos1, RF_Hos2, RF_Hos3

10. Slide ----- ----- ----- ----- -----
		(2) Um Vorhersagen für ein Test-Set zu generieren, kann es sein, dass die Entscheidungsbäume der fold-wise-RFs 
		    gepruned werden müssen.
            --> pruning wird in unserem Fall angewandt, wenn ein RF SplitVariablen enthält, die für das Test-Set 
                nicht vorhanden sind.

            	Pruning wird anhand des untenstehenden Beispiels erklärt:
                	> der Entscheidungsbaum links benutzt 'weight' & 'height' als split-variablen & hat 3 terminal nodes
					
					> Dieser Entscheidungsbaum kann nicht angewandt werden, auf Beobachtungen denen die Variable 'height' fehlt!
					  --> ABER wenn wir den Entscheidungsbaum prunen, kann er Vorhersagen für solche Beobachtungen treffen!
					  	  --> dazu wird der Entscheidungsbaum zurechtgeschnitten, sodass jeder Node, der mit einer  
					  		  unbekannten Variable splitted zu einem Terminal Node wird 
					  		    >> in unserem Beispiel also der Node, der mit 'height' splitted
					  	   --> Der geprunde Entscheidungsbaum kann dann Vorhersagen treffen, auch wenn die Test-Obs. 
					  	       gar nicht in 'height' beobachtet wurde


11. Slide ----- ----- ----- ----- ----
        (2) Der Prozess um eine Predicition für ein Test-Set zu generieren ist in der unten stehenden Grafik dargestellt
			
			Zuerst wird jedes Fold-wise fitted model nach einer Vorhersage gefragt:

				> RF(Hospital2) wurde auf den Blocks 'Clinical' & 'RNA' trainiert 
					-> Vorhersage mit dem Modell auf den Tést-Daten regulär!


				> RF(Hospital1) & RF(Hospital3) wurden beide auf einem Fold mit 'CNV' trainiert
					--> Block CNV nicht vorhanden für das Test-Set
						--> die Entscheidungsbäume dieser RFs müssen gepruned werden
			    			--> Nach dem Pruning kann das Modell dann Vorhersagen regulär treffen / 
			    			    bzw. ist gar nicht mehr benutzbar


	(3) Die finale Vorhersage entspricht dann dem gewichteten / ungewichteten Mittelwert der fold-wise Predicitons!
				> unweighted: --> Mittelwert der fold-wise predicitions
				> weighted:   --> Benutze die OOB-Accuracy/ F-1-Score der gepruneden Fold-Wise Models als Gewicht, um 
				                  die einzelnen Vorhersagen zu gewichten

	- Dieser Ansatz verwendet die Daten sehr effizient und verwirft keine einzige Beobachtung/ Feature

[9. - 11. ~3:00]
----- Benchmark Experiment ---------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
12. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zu dem Kapitel "Benchmark Experiments"
	
	>> Zuerst werden kurz die verwendeten METRIKEN vorgestellt!

		- Allgemein werden Metriken verwendet, um zu bewerten, wie gut die Vorhersagen eines Modells mit den eigentlichen
		  Daten übereinstimmen.

		- Es werden nur Metriken für 'binäre Klassifikation' vorgestellt, dabei sind alle insensibel gegenüber Class-Inbalaces!

	- Der 'F-1 Score' ist das harmonische Mittel aus der Precsion und dem Recall [1. = precision || 2. = recall]

	- Die 'balanced accuracy' berechnet die Accuracy seperate pro Responseklasse, und entspricht dann dem Durchschnitt 
	  der class-wise accuracies!

	- Der 'Matthews Correlation Coefficent' ist die diskretisierung der 'Pearson-Correlation' für binäre Variablen

		--> Alle diese Metriken sind am besten mit dem Wert '1' und schlechter umso niedriger ihr Wert!

[12. 0:40 - 0:50]
13. Slide ----- ----- ----- ----- -----
	>> Sprechen wir nun über die erste Quelle von Multi-Omics Daten --> 'The Cancer Genome Atlas' - kurz TCGA

	- Insgesamt wurden 21 Datensätze von meinem Betreuer - Dr. Hornung - zur Verfügung gestellt. 

	- Die Variable 'gender' wurde als binäre response variable genutzt!
		- Auch wenn das kein sinnvoller klinischer outcome ist, ist vollkommen ausreichend für eine methodische Untersuchung
			--> 14 DFs blieben übrig, nachdem 7 DFs entfernt wurden die keine gender variable hatten 

	- Die 14 Datensätze haben alle die gleichen 5 Blöcke, wobei die Anzahl der Variablen in diese Blöcken reduziert wurde,
	  um den computionalen Aufwand zu reduzieren.
	  	--> Die Tabelle zeigt die durchschnittliche Anzahl an Variablen pro Block - einmal für die orginal daten &
	  	                                                                            einmal für die dimensions-reduizerten  
	  	                                                         [z.B. 90% der Variablen aus 'Mutation' wurden entfernt!] 

[13. ~1:00]
14. Slide ----- ----- ----- ----- -----
	>> Da alle 14 TCGA DFs komplett beobachtet sind & keine fehlenden Daten enthalten, muss block-wise missingness induziert
	   werden, sodass die Daten für das Benchmark experiment verwendet werden können 

	- Insgesamt gibt es vier verschiedene patterns:
		- Das erste zeigt den Fall, in dem die verschiedenen folds alle in einem einzelnen omics block & dem clinical 
		  Block beobachtet wurden
		- In dem zweiten Pattern ist der erste Fold in alle 5 Blocks beobachtet, der 2. Fold in nur 4 Blocks, der 3. Fold
		  in 3 Blocks usw. 
		- In dem dritten Pattern wurden die beobachtetn Blöcke pro Fold zufällig gezogen
		- In dem letzten Pattern wurden 2 blocks zu einem einzelne vereint [RNA & miRAN + Mutation & CNV] & jeder Fold
		  ist in einem Omics-Block und einem Clinical Block beobachtet!

[14. ~0:40]
15. Slide ----- ----- ----- ----- -----
	>> Um die verschiedenen Ansätze auf den TCGA Daten zu evaluieren wird folgender Algo. verwendet.

		- Zu Beginn wird ein Datensatz D, ein Approch APP und ein Block-wise missingness pattern PATT ausgewählt.
			> Der komplett beobachete Datensatz wird zuerste in 5 gleich große CV-folds eingeteilt
				> ein CV-Fold wird als Test-Set genommen & die restlichen vier als Train-Set
				> In das Train-Set wird dann die block-wise pattern PATT induziert
				> Der Approach wird dann auf dem gleichen Test-Sets mit verschiednen Kombinationen an beobachteten Blöcken evaluiert:
						- test-set das in allen Blöcken beobachtet wurde
						- alle möglichen Kombinationen des test-sets, bei den ein Block fehlt
						- alle möglichen Kombinationen des test-sets, bei den zwei Blöcke fehlen, etc...

[15. ~ 0:50]
16. Slide ----- ----- ----- ----- -----
	>> Kommen wir nun zur zeiten Quelle für Mulit-Omics Daten - die 'clinical asthma data'

	- Hierbei handelt es sich um einen 'real-world' Datensatz, der von der Arbeitsgruppe von 
	  Prof. Dr. med. Bianca Schaub kommt 
	- Die Daten haben eine binäre response variable (Asthma Ja/Nein) & ungefähr gleich viel Beobachtungen pro response-klasse
	- Um die verschiedenen Ansätze zu evaluerien wurde reguläre 5-fold CV angewandt
	- Die Daten bestehen aus 6 Blocks
		- Die einzelnen Blocks, sowie deren Anzahl an Beobachtungen und Variablen sind in der unteren Tabelle dargestellt!
			--> desto weniger Beobachtungen pro Block, desto höherer der Aufwand, um die Daten zu erheben

----- Results ----------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
17. Slide ----- ----- ----- ----- ----- 
	>> Kommen wir nun zu den Ergebnissen der Benchmark Experimente.
	   Mit den verschiedenen Patterns werden nur die besten Methoden miteinander verglichen.
	   	-> Für den SB-Approach steht in der Legende immer, welcher Block verwendet wurde 
	   	-> Für den BW- & FW-Approach jeweils welche Gewichtung [OOB-Metrik] verwendet wurde 


	 --> Der Plot zeigt die Ergebnisse der verschiedenen Ansätze für Pattern1.
	     Die verschiedenen Test-Situationen sind auf der x-Achse dargestellt!
	     [full = komplett beobachtetes Test-Set, miss1_A = Test-Set in dem Block 'A' fehlt, miss1_B ...] - 
	     & Die y-Achse zeigt den etnsprechenden F-1 Score

	     - Sowohl der Fold-, als auch der Block-wise approach hatten ihre beste Perfromance mit dem 'F-1 Score' als OOB-Weight-Metric!
	     - Der Single-Block Approach war am besten mit dem Block A [entspricht in dem Pattern 'CNV']

	     - Der Fold-Wise, Imputation & Block-Wise approach können in allen 20 test-Situations Vorhersagen treffen
	     - Der Single-Block approach nur in den Test-Situationen mit einem feature-block 'A' [9/20 Test-Situationen]
	     - Der Complete Case Approach kann nur in den Test-Situationen Vorhersagen treffen, in denen das Trainingset
	       'complete cases' beinhaltet [9/20 Testsituations der Fall]

	 --> Der Fold-Wise approach hat den besten median F-1 Score in 11 test-situationen, der Imputation approach in 4 
	     situationen und der blockwise approach in 3 test-situationen
	     	--> CC & SB haben kein einziges mlal das beste Ergebniss!

18. Slide ----- ----- ----- ----- ----- 
	-> Der Plot zeigt die Ergebnisse der verschiedenen Ansätze für Pattern2.
		   Wieder zeigt die x-Achse die verschiedenen Test-Situationen & die y-Achse den etnsprechenden F-1 Score

	     - Sowohl der Fold-, als auch der Block-wise approach hatten ihre beste Perfromance mit dem 'F-1 Score' als OOB-Weight-Metric!
	     - Der Single-Block Approach war am besten mit dem Block D [entspricht in dem Pattern 'CNV']

	     - Der Fold-Wise, Imputation, Block-Wise & complete-Case approach können in allen 20 test-Situations Vorhersagen treffen
	     - Der Single-Block approach nur in den Test-Situationen mit einem feature-block 'D' [9/20 Test-Situationen]

	 --> Der block-wise und Imputaion approach haben jeweils den besten median F-1 Score in 8 Test-Situations

	     --> Single-Block/ Complete Case/ Fold-Wise Approach Approach never led to the best median F-1 Score!

19. Slide ----- ----- ----- ----- ----- 
	-> Der Plot zeigt die Ergebnisse der verschiedenen Ansätze für Pattern3.
		   Wieder zeigt die x-Achse die verschiedenen Test-Situationen & die y-Achse den etnsprechenden F-1 Score

	   	 - Sowohl der Fold-, als auch der Block-wise approach hatten ihre beste Perfromance mit dem 'F-1 Score' als OOB-Weight-Metric!
	     - Der Single-Block Approach war am besten mit dem Block A [entspricht in dem Pattern 'CNV']

	     - Der Fold-Wise, Imputation & Block-Wise approach können in allen 6 test-Situations Vorhersagen treffen
	     - Der Complete-Case Approach kann in 5/6 Test-Situationen Vorhersagen treffen
	     - Der Single-Block approach in gerade mal 3 der 6 test-situationen!

	 --> Der FoldWise Approach in 4 test-situations den besten median F-1 Score
	     & der Complete-Case Approach in einer test-situation!
	     
	     --> Single-Block/ Complete Case Approach haben in keiner einzigen Test-Situation den besten median F-1 Score!


20. Slide ----- ----- ----- ----- ----- 
	-> Der Plot zeigt die Ergebnisse der verschiedenen Ansätze für Pattern4.
		   Wieder zeigt die x-Achse die verschiedenen Test-Situationen & die y-Achse den etnsprechenden F-1 Score
		   	--> Da die Daten Pattern4 nur aus 3 Blöcken und nicht 5 bestehen, gibt es hier weniger test-situationen

	   	 - Sowohl der Fold-, als auch der Block-wise approach hatten ihre beste Perfromance mit dem 'F-1 Score' als OOB-Weight-Metric!
	     - Der Single-Block Approach war am besten mit dem Block B [entspricht in dem Pattern 'Mutation & CNV']

	     - Der Fold-Wise, Imputation, Block-Wise & complete-Case approach können in allen 20 test-Situations Vorhersagen treffen
	     - Der Complete-Case Approach kann in 16/20 Test-Situationen Vorhersagen treffen
	     - Der Single-Block approach nur in den Test-Situationen mit einem feature-block 'A' [9/20 Test-Situationen]

	 --> Der block-wise approach hat in 10 test-situationen den besten median F-1 Score
	     Der Imputation Approach hat in 4  test-situationen den besten median F-1 Score &
	     Der FoldWise Approach in 2 test-situations
	     
	     --> Single-Block, Complete Case & block.wise Approach haben in keiner einzigen Test-Situation den besten median F-1 Score!

21. Slide ----- ----- ----- ----- ----- 
	Auf clincal-astha data, wurden nicht nur die RF-Adaptions aus dieser Arbeit vergleichen, sondern auch mit
	den Methoden von Hagenberg'S Masterarbeit

	> In der Arbeit wurden zwei verschiedene Priority-Lasso Adaptions vorgestellt, die direkt mit blockwise fehlenden Daten
	  umgehen können! 
	  	- PL - ignore - das noch unterteilt wurde in: 'PL - ignore, intercept' & 'PL - ignore, zero'
	  	- PL - Impute - das noch unterteilt wurde in: 'PL - Impute, max. n' & 'PL - Impute, max. blocks'

	  	Diese Ansätze wurden evaluiert für die verschiedene Einstellungen [e.g. verschiedene Prioritäten der Blocks, ...]

	> Zudem wurde noch die mdd-sPLS Methode von Lorenzo et al. als Reference Methode verwerndet

22. Slide ----- ----- ----- ----- ----- 
	Der Plot zeigt die Ergebnisse der Ansätze meiner Arbeit und aus Hagenbergs Arbeit für die clinical asthma data!

	Die y-Achse zeigt den F-1 Score und die x-Achse die verschiedenen Ansätze - hierbei wurden auch wieder nur die besten verwendet!

		> Single-Block Approach war am besten mit Block 'Questionaire'
		> Block & Fold-wise Approach waren am besten mit dem F-1 Score als weight metric!
		> Für die verschiedenen PL-Ansätze steht die Priorität der Blöcke für die Vorhersagen in den eckigen Klammern
			- e.g. "PL-ignore, zero 1, 2, 3" 
				-->  Der PL, ignore zero Ansatz der nur die Blöcke 1, 2, 3 [auch in der Reihenfolge] zum Borhersagen benutzt

			> Die schlechtesten Ergebnisse erzielt der Block-Wise Approach gefolgt vom SB- & CC-Approach
			> Der mdd-sPLS Ansatz ist nur leicht bessr als der CC-Approach und schlechter als das schlechteste 
			  Ergebniss der PL-Ansätze
			> Der FW- & Imputation-Approach erzielen die besten Ergebnisse von allen RF-Anpassungen
			> Díe 3 besten Ansätze sind alle erreicht mit 'PL - ignmore, zero', wobei versch. Prioritäten & 
			  subsets der Blocks für die Predicition benutzt wurden!

23. Slide ----- ----- ----- ----- ----- 
	>> Kommen wir nun zu dem letzten Kapitel 'Discussion & Conclusion'

		- Bei den Approaches aus dieser Arbeit, lässt sich folgendes sagen:
			- der CC & SB-Ansatz zu den schlechtesten Ergebnissen geführt hat!
			- der BW- & FW-Ansatz haben in allen Situationen am besten mit dem F-1 Score als weight-metric funktioniert!
			- BW & FW-Anstz haben gegensätzliches Verhalten	
				--> Situationen wo FW sehr gut ist, ist BW eher schlecht & genauso auch andersrum!
			- Die Ergebnisse des Imputation Ansatzes sind vergleichbar mit denen des FW- & BW-Ansatzes!

24. Slide ----- ----- ----- ----- ----- 
	- Bei den Approaches aus Hagenbers Arbeit, lässt sich folgendes sagen:
			- die verschiedenen Ansätze hatten die schlechteste Performance mit der 'naiven' Block-Priority 
			  [weniger fehlende Daten --> höhere Priorität!]
			- mdd-sPLS war der schlechteste Ansatz & 'PL, ignore' der beste!
			- Zwischen den Ansätzen  'PL - ignore, intercept' & 'PL - ignore, zero' gibt es kaum Unterschiede

25. Slide ----- ----- ----- ----- ----- 
	- Vergleich der Ansätze beruht nur auf 'clinical asthma data'
	- Imputation & FW-Approach sind besser als mDD-sPLS & 'PL, ignore' mit der naiven block-priority!
	- Mit anderen block prioritäten, sind die PL Ansätze allerdings deutlich besser!
	- Es sollte noch erwähnt werden, dass evtl. eine selection-bias entstanden ist, da die PL mit viel 
	  mehr unterschiedlichen settings ausprobiert wurden!

	  --> Die Wahl des optimal Ansatzes hängt von dem Vorwissen des Users zu den Daten ab!
	  	- Falls man weiß, welche Blöcke wichtig für den response sind, sollten die 'PL; ignore' Ansätze verwendet werden!
	  	- Falls man aber nicht weiß welche Blöcke wichtig sind & welche nicht, sind die RF-Ansätze die besser Wahl!
	  		--> besonders der FW & BW-Approach, da diese eine OOB-Metric benutzen um die Importance der versch.
	  		    Blöcke & Folds zu schätzen!

26. Slide ----- ----- ----- ----- ----- 
	- Für die weitere Forschung, wäre es interessant die mdd-sPLS, RF-Adaptions & PL-Approaches auf mehr als nur dem 
	  clincal asthma data zu vergleichen!
	- Der FW-Approach könnte direkt in C & Java implemetniert werden, umso dessen Geschwindkeit zu erhöhen
	  [momentan ist der Ansatz rein in R implemntiert]
	- Eine Kombination des FW-Approaches und der Idee aus dem BlockForest Article könnte viel versprechend sein!
		--> Berücksichtigung der block-structur bei der split-point selection!