NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES PRESENTATION --- NOTES

------------------------------------------------------------------------------------------------------------------------
----- INTRO ------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
1. Slide ----- ----- ----- ----- -----
	- Herzlich wilkommen zu der Abschlusspräsentation meiner Masterarbeit.
	- Die Arbeit wurde von Dr. Hornung betreut und trägt den Titel
		'A comparison study of predicition approaches for multiple training data sets & test data with block-wise missing values'

2. Slide ----- ----- ----- ----- -----
	>> Zuerst schauen wir uns an, wie die Präsentation strukturiert ist!
 
		[1]	- Zu Beginn wird erklärt, was 'block-wise missingness' ist und Gründe dafür, wie sie enstehen kann

		[2] - Dann kommen wir zu dem Methoden-Teil. 
		    - Hier wird kurz das 'RandomForestModel' erklärt & anschließend die darauf aufbauenden Ansätze, um mit 
		      'block-weise fehlden Daten' umzugehen: 
		    		- CC Approach
		    		- Single-Block Approach
		    		- Imputation Approach
		    		- Block-Wise Approach
		    		- Fold-Wise Approach

		[3] - Im Teil 'Benchmark Experiment' werden die Metriken, Datensätze & Techniken vorgestellt, um die Güte
		      der verschiedenen Ansätze zu bewerten

		[4] - Anschließend werden die Ergebnisse dieser Benchmark-Experimente vorgestellt

		[5] - Zum Schluss werden diese Ergebnisse diskutiert, es wird ein Fazit gezogen & Vorschläge für die weitere 
		      Forschung in diesem Themen-Gebiet gemacht

------------------------------------------------------------------------------------------------------------------------
----- Block-wise Missingness -------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
3. Slide ----- ----- ----- ----- -----
	>> Block-Wise missingness ist ein spezieller Fall von fehlenden Daten, der besonders oft im Context von Multi-Omics 
	   Daten auftritt

	 - Die Tabelle zeigt ein Beispiel für einen Datensatz mit block-weise fehlenden Daten
	  	- Insgesamt hat der Datensatz 105 Variablen und 8 Beobachtungen
	  		- Die Variablen 'weight', 'height', 'income' & 'education' sollten selbsterklärend sein
	  		- Die variablen 'g1', ..., 'g100' stehen für omics daten & 'Y' ist die binäre response-variabel

	  	- Daten mit block-wise missingness bestehen immer aus unterschiedlichen 'Blocks' und 'Folds'
	  		- ein BLOCK beschreibt einfach ein set von variablen, die inhaltlich zusammen hängen
	  			- in unserm Beispiel gibt es 3 Blocks:
	  				- 'Block1' besteht aus den Variablen 'weight' & 'height' & steht für physische Eigenschaften 
				    - 'Block2' besteht aus den Variablen 'income' & 'education' & steht für ökonomische Eigenschaften 
				    - 'Block3' besteht aus den Variablen 'g1',...,'g100' & steht für biologische Eigenschaften 

			- a FOLD beschreibt ein set von Observations, die in den gleichen Blöcken beobachtet wurden
				- in unserem Beispiel gibt es 3 Folds:
					- 'FOLD1' besteht nur aus den Beobachtungen, die in Block1 & Block2 beobachtet wurden
					   [also allen Beobachtungen, die in 'weight', 'height', 'income' & 'education' beobachtet wurden]
					- 'FOLD2' besteht nur aus den Beobachtungen, die in Block1 & Block2 beobachtet wurden
			        - 'FOLD3' besteht nur aus den Beobachtungen, die in Block2 & Block3 beobachtet wurden
		
					- Die einzige Variable, die für alle Observations gemeinsam haben müssen ist die response variabele 'Y'

4. Slide ----- ----- ----- ----- -----
	>> Es gibt zwei Hauptgründe dafür, dass Block-Wise Missingness häufig im Kontext mit Multi-Omics Daten entsteht.

		>1< - Erstens, das erheben von 'omics Daten' ist deutlich teurer und komplexer ist, als es für normale 
		      klinische Daten. Darum können omics Daten meist -wg. monetären/ technischen Gründen - nicht für ALLE 
		      Teilnehmer einer Studie erhoben werden, sodass der Datensatz der Studie block-wise fehlende Daten enthält

		>2< - Der zweite ist, dass Datensätze von verschiedenen Quellen zusammengetragen werden. 
		 	- So ein Fall ist besipielhaft gezeigt in der untenstehenden Grafik. 
		 		- Zu sehen sind 3 verschiedene Datenquellen - von 3 verschiedenen Krankenhäusern, die alle Research im 
		 		  Bezug auf die Response-Variable 'Y' gemacht haben ('Asthma' - ja/nein?!)
				- Auch wenn die Krankehäuser für die gleiche Krankheit (Y) forschen, müssen sie nicht zwangsläufig die
				  gleichen Daten erheben
				- Wenn man diese zusammenfügt, entsteht Block-Wise missingness, weil die Beobachtungen aus den 
				  verschiedenen Krankenhäusern in verschieden Blocks beobachtet wurden
				  	--> Hospital1 hat nur die Blöcke 'CNV' & 'Clinical', sodass den Beobachtungen von dem Krankenhaus
				  	    nicht in den Blöcken 'RNA' & 'miRNA' beobachtet sind!

------------------------------------------------------------------------------------------------------------------------
----- Methoden ---------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
5. Slide ----- ----- ----- ----- -----
	>> Kommen wir jetzt zu den Methoden:

	- Zuerst wird das RF-Model kurz vorgestellt, weil es die Grundlage für die nachkommenden Ansätze ist

	- Also: > Das RF-Model wurde 2001 von Breimann vorgestellt & ist eine ensemble methode, die decision-trees als 
	        base-learner benutzt. 
	        > Um diese decision-trees zu trainieren, wird eine leicht veränderter Bagging Ansatz verwendet.
	        > Die Vorhersage eines RF entsprichen dem durchschnitt der Vorhersagen der einzelnen decision-trees
	        > Die 'predicitive-performance' eines RF-Models kann intern mit dem OOB-Error berechnet werden - 
	          dieser OOB-Error is fast identisch mit dem einer N-fold cross-validation

6. Slide ----- ----- ----- ----- -----
	>> Der Complete-Case approach ist der erste RF-Ansatz um mit block-wise fehlenden Daten umzugehen

	- Die Idee ist es, dass die TrainingsDaten - in Bezug auf das Test-Set - so bearbeitet werden, dass sie keine 
	  Block-wise fehlende Daten mehr beinhalten!

	  Dazu:	- werden alle folds aus den Trainingsdaten entfernt, die einen Block enthalten, der für das Test-Set nicht 
	          vorhanden ist.
	          >> in dem untenstehenden Beispiel, haben wir ein Test-Set mit den Blocks 'Clinical' & 'CNV' - 
	             Aus den Trainingsdaten werden jz Hospital 2 & 3 entfernt, weil diese in CNV/ Clinical nicht beobachtet
	             wurden

	        - Dann werden alle Blöcke aus dem übrigen Folds entfernt, die nicht für die Test-Daten vorhanden sind.
	        	--> RNA & miRNA werden entfernt

	        --> Auf den übrigen Daten kann ein RF regulär trainiert werden & anschließend Vorhersagen für das Test-Set 
	            treffen

	- Dieser Ansatz hat 2 Nachteile:
		[1] Die Daten werden nicht besonders effizient benutzt & es werden viele Verworfen
		[2] Das 'Processing' der Trainings-Daten kann auch in einem leeren Datensatz enden, aus dem alle Folds & Blocks 
		    entfernt wurden, sodass der Ansatz in solchen Fällen dann keine Vorhersagen liefern kann

7. Slide ----- ----- ----- ----- -----
	>> Der nächste RF-Ansatz um mit blockwise fehlenden Daten umzugehen ist der 'Single-Block' Approach

	- die Idee ist es, dass ein RF auf einem einzelnen feature-block trainiert wird [den Test- & Train gemeinsam haben]
	  um so Vorhersagen für das Test-Set zu treffen.

	Dazu: - werden zu Beginn alle Blöcke, die sich Test- & Train-Set teilen extrahiert & basierend darauf RFs trainiert.
			>> In untemstehenden Beispiel teilen sich die Train- & Test-Daten die Blöcke 'CNV'  & 'Clinical',
			   sodass auf jedem dieser Blöcke ein RF trainiert werden kann.
		  - Diese trainierten RFs können dann Vorgersagen für das Test-Set liefern. 
		   	>> In dem Beispiel würde jede Beobachtung aus dem Test-Set eine Vorhersage erhalten - einmal basierend auf dem
		   	   CNV Block und einmal basierend auf dem Clinical Block.

		  --> Dieser Ansatz verwendet die Daten wieder nicht besonders effizient & kann nur dann eingesetzt werden, wenn
		      sich Test- & Train-Set mindestens einen Block teilen.

8. Slide ----- ----- ----- ----- -----
	>> Der nächste Ansatz, um mit block.wise fehlenden Daten umzugehen ist der 'Imputation Approach'

	- die Idee ist es, die fehlenden Daten in dem Trainingsset zu imputieren, sodass die Daten danach keine fehlenden 
	  Werte mehr beinhalten. Dann wird basierend auf den Blocks die sich Test- & imputed Train-Set teilen ein RF 
	  gefittet & zum Vorhersagen auf dem Test-Set verwendet.

	Dazu:	- werden zu allererst die fehlenden Werte in dem Trainingset imputiert mit der 'missForest' Methode
				--> Der Datensatz ist danach vollständig beobachtet
			- Auf den Blöcken, die das imputierte TrainingSet und TEst-Set gemeinsam haben, kann dann ein RF regulär
			  trainiert werden und Vorhersagen für das Test-Set generieren!

	- Dieser Ansatz verwendet die Daten sehr effizient und verwirft gar keine Traininsdaten
	- Der Nachteil des Ansatzes besteht darin, dass
		- 1. Viele fehlende Daten in dem Train-Set führen zu unverlässlichen Imputationen
		- 2. Falls die Trainingsdaten von verschiedenen Quellen zusammengetragen wurde, macht das die Imputation 
		     unzuverlässig, weil die Datensätze heterogen sind!

9. Slide ----- ----- ----- ----- -----
	>> Der nächste Ansatz ist der Block.weise Ansatz

	- Die idee ist, dass auf jedem Block in den Trainingsdaten ein seperates RF Model gefittet wird. 
	  Für Vohersagen auf dem Test-Set werden diese block-wise Vorhersagen dann aggregiert.

	Dazu:	- wird auf jedem Feature-Block in den Trainingsdaten ein sepertes RF-Model geftitted
				>> In dem Beispiel hätte man also 4 seperate Modelle -  RF_clincial, RF_CNV, ...

			- Für eine Vorhersage auf dem Test-Set, werden alle 'block-wise' fitted models nach einer predicition gefragt
			  Nur die, die auf einem BLock traininert wurden, der auch für das Test-Set vorhanden ist, können eine 
			  Vorhersage liefern.
			  	>> In dem Beispiel können 3 der 4 Modelle eine Vorhersage liefern - RF_Clincial, RF_RNA & RF_miRNA
			  	   nur das block-wise fitted Model 'RF_CNV' kann keine Vorhersage treffen, weil das Test-Set in dem
			  	   Block nicht beobachtet wurde

			- Diese einzelnen Vorhersagen werden dann aggregiert für eine final Vorhersage
				- Entweder nimmt man den reinen - also ungewichteten - Average
				- ODER man nimmt den gewichteten average und gewichtet die block-wise Vorhersagen mit dem OOB-Error
				       der block-wise models
				       	--> besser OOB MEtric --> höheres Gewicht/ Beitrag für die gesamt predicition
				       		[als Metrics wurde einemal die 'Accuracy' & einmal der 'F-1 Score' verwendet]

	- Dieser Ansatz verwendet die Daten sehr effizient und verwirft keine einzige Beobachtung/ Feature!

10. Slide ----- ----- ----- ----- -----
	>> Nun kommen wir zu dem letztem RF-Ansatz - dem Fold-Wise Approach

	- Die Idee des Ansatzes besteht darin, auf jedem Fold in den Trainingsdaten ein Modell zu fitten. Für die Vorhersage
	  auf einem Test-Set, werden die Vorhersagen der fold-wise models aggregiert.

	Dazu:	- Wird auf jedem Fold ein seperates RF-Model gefittet, sodass man so viele Modelle hat, wie die TrainingsDaten
	          Folds hat
	          	>> gezeigt in dem untenstehenden Beispiel

	         - Für eine Vorhersage auf dem Test-Set, wird jedes Fold-Wise Molde nach einer Vorhersage gefragt.
	         	--> Nur die, die auf einem Fold trainiert wurden, der mindest einen Block mit dem Test-Set gemeinsam hat,
	         	    können Vorhersage treffen - dafür kann es aber sein, dass ein Modell geprunded werden muss.
	                 >> Pruning wird auf der nächsten Folie genauer erklärt.

	         - Diese einzelnen Vorhersagen werden dann aggregiert für eine final Vorhersage
	         		>> Wird auch auf der nächsten Slide genauer erläutert.

11. Slide ----- ----- ----- ----- ----
	- PRUNING:
		- Pruning - zu deutsch stutzen - kann auf einen decision-tree angewandt werden, wenn dieser eine SplitVariable enthält,
		  die für eine Test-Beobachtung vorhanden ist.
		- e.g.  > der decision-tree links benutzt 'weight' & 'height' als split-variablen & hat 3 terminal nodes
				> Dieser decision-tree kann nicht angewandt werden, wenn die Beobachtung 'height' nicht hat.
				  ABER wenn wir den decision-tree prunen (stutzen), dann kann er Vorhersagen treffen für Beobachtungen 
				  ohne 'height'
				  	--> schneide den decision-tree zurecht, sodass jeder Node, der mit einer unbekannten Variable splitted
				  	    zu einem Terminal Node wird
				  	    --> Kann dann Vorhersagen treffen, auch wenn Test-Obs. gar nicht in 'height' beobachtet wurde
				> Wenn ein decision-tree an dem ersten Split gepruned werden muss, ist der decision-tree nicht mehr verwendbar 
				  & wird komplett von dem Entscheidugsbaum entfernt!

	- Predicitons:
		- Jedes Fold-wise fitted model wird nach einer Vorhersage gefragt.
			> RF(Hospital2) wurde auf den Blocks 'Clinical' & 'RNA' trainiert
				-> Vorhersage mit dem Modell auf den Tést-Daten regulär!

			> RF(Hospital1) wurde auf den Blocks 'Clincial' & 'CNV' trainiert
		    	--> Die einzelnen Decision-Trees müssen gepruned werden, weil sie unter umständen 'CNV' features als 
		    	    SplitVariablen benutzen, die für das Test-Set nicht vorhanden sind.
		    	    --> Nach dem Pruning kann das Modell dann Vorhersagen regulär treffen!

		    > diese fold-wise predicitons werden dann aggregiert zu einer finalen Vorhersage
				> unweighted: --> Mittelwert der fold-wise predicitions
				> weighted:   --> Benutze die OOB-Accuracy/ F-1-Score der gepruneden Fold-Wise Models als Gewicht, um 
				                  die einzelnen Vorhersagen zu gewichten

	- Dieser Ansatz verwendet die Daten sehr effizient und verwirft keine einzige Beobachtung/ Feature -  wie auch der BW approach!


------------------------------------------------------------------------------------------------------------------------
----- Benchmark Experiment ---------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
12. Slide ----- ----- ----- ----- -----
	>> Kommen wir jetzt zu den Benchmark Experimenten
		--> Als erstes die Metriken

	- Metriken werden verwendet, um zu bewerten, wie gut die Vorhersagen eines Modells mit den eigentlichen Daten übereinstimmen.

	- Da nur Datensätze mit binärem Response verwerndet wurden, werden nur Metriken für 'binäre Klassifikation' vorgestellt!
	  Alle Metriken sind - anders als z.B. die accuracy - insensibel zu Class Inbalaces in der response variable

	- Der 'F-1 Score' ist das harmonische Mittel aus der Precsion und Recall Metric [1. = precision || 2. = recall]
	- Die 'balanced accuracy' berechnet die Accuracy seperate pro Responseklasse und ist der Durchschnitt der class-wisen
	  accuracys!
	- Der 'Matthews Correlation Coefficent' ist die diskretisierung der pearson correlation für binäre Variable

	--> Für alle Metriken gitl, dass sie am besten sind mit dem Wert '1'
		Der 'F-1 Score' & die 'balanced accuracy' haben den schlechtesten Wert mit 0 & bei dem MCC bei -1

13. Slide ----- ----- ----- ----- -----
	>> Sprechn wir nun über die erste Quelle von Multi-Omics Daten --> 'The Cancer Genome Atlas' - kurz TCGA

	- Insgesamt wurden 21 Datensätze von meinem Betreuer zur Verfügung gestellt. 
	  Die Daten wurden bereits bearbeitet 	- einmal die fehlenden Daten im Block 'Clincial' wurden imputiert!
	  										- kategoriale Variablen wurden in binäre numerische umgewandelt!
	  	--> 21 komplett Beobachtete Datensätze

	- Die Variable 'gender' aus dem Block 'Clinical' wurde als binäre response variable ausgewählt
		- Auch wenn das kein sinnvoller klinischer outcome ist, ist es für methodische Forschung in Ordnung diesen zu verwenden
			--> 7 der 21 DFs hatten keine Gender variable und wurden entfernt, sodass 14 DFs übrig blieben

	- Die 14 Datensätze haben alle die gleichen 5 Blöcke, wobei die Anzahl der Variablen in diese Blöcken reduziert wurde,
	  um den computionalen Aufwand zu reduzieren.
	  	--> Die Tabelle zeigt die durchschnittliche Anzahl an Variablen pro Block - einmal für die orginal daten &
	  	                                                                            einmal für die dimensions-reduizerten   

	  	    >> TABLE:	- clinical >> none
	  	     			- miRNA    >> 50%
	  	     			- Mutation >> 90%
	  	     			- CNV      >> 95%   
	  	     			- RNA      >> 85%

14. Slide ----- ----- ----- ----- -----
	>> Da alle 14 DFs komplett beobachtet sind, muss block-wise missingness induziert werden, für die benchmark experimente

	- Insgesamt gibt es vier verschiedene patterns:
		- Das erste zeigt den Fall, in dem die verschiedenen folds alle in einem einzelnen omics block & dem clinical block
		  beobachtet wurden
		- In dem zweiten Pattern ist der erste Fold in alle 5 Blocks beobachtet, der 2. Fold in nur 4 Blocks, der 3. Fold in 3 Blocks usw. 
		- In dem dritten Pattern wurden die beobachtetn Blöcke pro Fold zufällig gezogen
		- In dem letzten Pattern wurden 2 blocks zu einem einzelne vereint & jeder Fold ist in einem Omics-Block
		  und einem Clinical Block beobachtet!

15. Slide ----- ----- ----- ----- -----
	>> Sprechen wir nun kurz über den Algorithmus, um die Ansätze auf den TCGA Daten zu evaluieren

		- Zu Beginn wird ein Datensatz D, ein Approch APP und ein Block-wise missingness pattern PATT ausgewählt.
			> Der komplett beobachete Datensatz wird zuerste in  5 gleich große CV-folds eingeteilt
				> ein CV-Fold wird als Test-Set genommen & die restlichen vier als Train-Set
				> In das Train-Set wird dann die block-wise pattern PATT induziert
				> Der Approach wird dann auf verschiedenen Test-Sets evaluiert:
						- fully observed test-set
						- test-set mit einem fehlendem Feature-Block, and so on!

16. Slide ----- ----- ----- ----- -----
	>> Kommen wir jetzt zu zeiten Quelle für Mulit-Omics Daten - die 'clinical asthma data'

	- Die Daten sind von der Arbeitsgruppe von Prof. Dr. med. Bianca Schaub an der 
	  'pädiatrische Klinik Dr. von Haunersches Kinderspital'
	- Die Daten haben eine binäre response variable - asthma Yes/No 
		- from totally 521 observations: 265 have a negative \& 256 have a positive response
	- Die Daten bestehen aus 6 Blocks:
			- Questionaire, Clinical routine diagnostigs, allergen sensatzion, Cyoktine expression data, gene expression dáta 1&2
		    - Die Anzahl an Beobachtungen pro Block spiegelt umgekehrt den Aufwand zur Generierung der Daten wider
		    	>> weniger observations --> höherer Aufwand die Daten zu erheben

17. Slide ----- ----- ----- ----- -----
	>> Der Algorthmus zeigt den Ablauf um die Methoden auf den clinical asthma data zu evaluieren
		- 1. Zuerst wählt man einen approch
		- 2. Der DF wird dann in 5 gleich große CV-folds aufgeteilt
			- einer dieser CV-folds dient als test-fold & die restlichen als train-fold
			- dann werden die patterns of BWM in dem Test-Set extrahiert
			  [daten beinhalten schon BWM --> obs. in test-set sind auch in unterschiedlichen blocks beobachtet worden] 
				--> Für jedes pattern of BWM in the test-set, the approach generates predicitons
			--> Metrik für den momentanen CV-fold wird bestimmt, indem wahren klassen mit den vorhergesagten verglichen werden


------------------------------------------------------------------------------------------------------------------------
----- Results ----------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
18. Slide ----- ----- ----- ----- ----- 
	>> Kommen wir nun zu den Ergebnissen zu sprechen. Die Analyse der Ergebnisse fällt eher knapp aus, da sich die 
	   Präsentation sonst zu lange ziehen würde.
	   Es werden nur die besten Methoden miteinander verglichen.
	   	-> Für den SB-Approach steht in der Legende immer, welcher Block verwendet wurde
	   	-> Für den BW- & FW-Approach jeweils welche Gewichtung [OOB-Metrik] zu den besten Ergebnissen geführt hat


	 --> Der Plot zeigt die Ergebnisse der Ansätze für die verschiedenen Test-Situationen - x-Achse - und die y-Achse 
	     zeigt den etnsprechenden F-1 Score

	     - Sowohl der Fold-, als auch der Block-wise approach hatten ihre beste Perfromance mit dem 'F-1 Score' als OOB-Weight-Metric!
	     - Der Single-Block Approach hatte die besten Ergebnisse mit dem feature-block 'A' [CNV in this pattern]

	     - Der Fold-Wise, Imputation & Block-Wise approach können in allen 20 test-Situations Vorhersagen treffen
	     - Der Single-Block approach nur in den Test-Situationen mit einem feature-block 'A' [9/20 Test-Situationen]
	     - Der Complete Case Approach kann nur in den Test-Situationen Vorhersagen treffen, in denen das Trainingset
	       'complete cases beinhaltet' [9/20 Testsituations der Fall]

	 --> Der Fold-Wise approach hat den besten median F-1Score in 11 test-situationen, der Imputation approach in 4 situationen
	     und der blockwise approach in 3 test-situationen
	     	--> CC & SB kein einziges das beste Ergebniss!


STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED 
STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED STOPPED 

19. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Single-Block approach are shown.
	- For each pattern of BWM the results are shown split by the block that was used for the training of the SB-Approach
	- Two things are standing out:
		- Firstly: The SB approach can only generate predicitons for the test-sets that contain the block, that has been initially used for the training
		           (e.g. pattern4 - 'A' can only provide predicitons for test-sets with 'A')
		- Secondly: The performance of a single-block model is the same for the various test-situations. This makes 
		            sense, as the SB approach only uses a single block for the predicition & the various test-situations
		            only differ in the observed blocks, BUT not the blocks itself!


20. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Imputation approach are shown.
	- It stands out, that the imputation approach can provide predicitons for all possible test-situations!


21. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Block-Wise approach are shown.
	- To each test-situation, the results are shown structured by the weight used to aggregate the predicitions
	- It stands out, that the BW approach can provide predicitons for all possible test-situations!
	- Furthermore, it can be seen, that the weight_metric has no influence in the test-situations 'single_A'-'single_CL'
		--> this makes sense, as the test-set only consits of a single block 
		   --> no aggregation of BW predicitons!
	- Else it can be seen, that in all patterns and almost all test-situations the performance of the BW approach is the
	  best with the 'F-1 Score' as weight metric!


22. Slide ----- ----- ----- ----- -----
	- Last but not least the results of the FW approach are shown
	- As the BW & Imputation approach, this approach can provide predicitons for each test-situation
	- Furthermore, it can be seen, that the weight_metric has no influence in the test-situations in which only a single
	  fold from the training data can be used 
	  	- e.g. with 'Pattern 1' the performance in the test-situations 'single A', 'single B', 'single C' and
              'single D' is equal for the different weight metrics. 
              	--> That is reasonable, as in these test-situations only a single fold-wise fitted random forest model can
                    provide predictions, as the training-set only has a single fold that can be used for these test-situations.
					--> no aggregation of FW predicitons!

23. Slide ----- ----- ----- ----- -----