PRESENTATION NOTES:

1. Slide ----- ----- ----- ----- -----
	- Herzlich wilkommen zu der Abschlusspräsentation meiner Masterarbeit.
	- Die Arbeit wurde von Dr. Hornung betreut und trägt den Titel
		'A comparison study of predicition approaches for multiple training data sets & test data with block-wise missing values'

2. Slide ----- ----- ----- ----- -----
	>> Zuerst schauen wir uns an, wie die Präsentation strukturiert ist!
 
		[1]	- Zu Beginn wird erklärt, was 'block-wise missingness' ist und Gründe dafür, wie sie enstehen kann

		[2] - Dann kommen wir zu dem Methoden-Teil. 
		    - Hier wird kurz das 'RandomForestModel' erklärt & anschließend die darauf aufbauenden Ansätze, um mit 
		      'block-weise fehlden Daten' umzugehen: 
		    		- CC Approach
		    		- Single-Block Approach
		    		- Imputation Approach
		    		- Block-Wise Approach
		    		- Fold-Wise Approach

		[3] - Im Teil 'Benchmark Experiment' werden die Metriken, Datensätze & Techniken vorgestellt, um die Güte
		      der verschiedenen Ansätze zu bewerten

		[4] - Anschließend werden die Ergebnisse dieser Benchmark-Experimente vorgestellt

		[5] - Zum Schluss werden diese Ergebnisse diskutiert, es wird ein Fazit gezogen & Vorschläge für die weitere 
		      Forschung in diesem Themen-Gebiet gemacht

[(1. + 2. Slide = 1.00)]

3. Slide ----- ----- ----- ----- -----
	>> Block-Wise missingness ist ein spezieller Fall von fehlenden Daten, der besonders oft im Context von Multi-Omics 
	   Daten auftritt

	 - Die Tabelle zeigt ein Beispiel für einen Datensatz mit block-weise fehlenden Daten
	  	- Insgesamt hat der Datensatz 105 Variablen und 8 Beobachtungen
	  		- Die Variablen 'weight', 'height', 'income' & 'education' sollten selbsterklärend sein
	  		- Die variablen 'g1', ..., 'g100' stehen für omics daten & 'Y' ist die binäre response-variabel

	  	- Daten mit block-wise missingness bestehen immer aus unterschiedlichen 'Blocks' und 'Folds'
	  		- ein BLOCK beschreibt einfach ein set von variablen, die inhaltlich zusammen hängen
	  			- in unserm Beispiel gibt es 3 Blocks:
	  				- 'Block1' besteht aus den Variablen 'weight' & 'height' & steht für physische Eigenschaften 
				    - 'Block2' besteht aus den Variablen 'income' & 'education' & steht für ökonomische Eigenschaften 
				    - 'Block3' besteht aus den Variablen 'g1',...,'g100' & steht für biologische Eigenschaften 

			- a FOLD beschreibt ein set von Observations, die in den gleichen Blöcken beobachtet wurden
				- in unserem Beispiel gibt es 3 Folds:
					- 'FOLD1' besteht nur aus den Beobachtungen, die in Block1 & Block2 beobachtet wurden
					   [also allen Beobachtungen, die in 'weight', 'height', 'income' & 'education' beobachtet wurden]
					- 'FOLD2' besteht nur aus den Beobachtungen, die in Block1 & Block2 beobachtet wurden
			        - 'FOLD3' besteht nur aus den Beobachtungen, die in Block2 & Block3 beobachtet wurden
		
					- Die einzige Variable, die für alle Observations gemeinsam haben müssen ist die response variabele 'Y'
[3.Slide: ~1.20]
[1-3 ~2:20]

4. Slide ----- ----- ----- ----- -----
	>> Es gibt zwei Hauptgründe dafür, dass Block-Wise Missingness häufig im Kontext mit Multi-Omics Daten entsteht.

		>1< - Der erste ist, dass das erheben von 'omics Daten' ist deutlich teurer und komplexer ist, als es für normale 
		      klinische Variablen der Fall ist. Darum können omics Daten meist nicht für ALLE Teilnehmer einer Studie 
		      erhoben werden, sodass der Datensatz zu der Studie block-wise fehlende Daten enthält

		>2< - Der zweite ist, dass oft Datensätze von verschiedenen Quellen zusammengetragen werden. 
		 	- So ein Fall ist besipielhaft gezeigt in der untenstehenden Grafik. 
		 		- Zu sehen sind 3 verschiedene Datenquellen - von 3 verschiedenen Krankenhäusern, die alle Research im 
		 		  Bezug auf die Response-Variable 'Y' gemacht haben 	- e.g. hat die Person 'asthma' - ja/nein!
				- Auch wenn die Krankehäuser für die gleiche Krankheit (Y) forschen, erhebt nicht jedes die gleichen 
				  variablen
				- Wenn man diese zusammenfügt, entsteht, dann Block-Wise missingness, weil die Beobachtungen aus den 
				  verschiedenen Krankenhäusern in verschieden Blocks beobachtet wurden
				  	--> Hospital1 hat nur die Blöcke 'CNV' & 'Clinical', sodass den Beobachtungen von dem Krankenhaus
				  	    nicht in den Blöcken 'RNA' & 'miRNA' beobachtet sind!
[4.Slide: ~1.10]
-- [1-4: 3:30] --

5. Slide ----- ----- ----- ----- -----
	>> Now I'll talk about the methods of the thesis:

	- Firstly the RF model is briefly introduced:
		- It was intoduced 19 years ago by Breiman and is an ensemble method, that uses decision trees as base learner
		- It uses a modified version of bagging to create bootstrapped decorrelated decision trees
		- The prediciton of the RF equals the average of all predicitions of its single decision trees
		- The RF can be evaluated internally with the OOB-error, whereby the OOB error is almost identical to that 
		  obtained by N-fold cross-validation

		- The algorithm to grow a RF is displayed: 
			> We train M single decision trees on a dataset n*p dimensional data-set D
			> For each tree, we draw a bootstrap sample of size n from D amd grow a tree on it.
				> To do so, draw 'mtry' variables as split candidates, pick the best splitting point among these 
				  split candidates and split the node in two child nodes
				  --> this is repeated until the child nodes contain less than 'n_min' observations


6. Slide ----- ----- ----- ----- -----
	>> Lets talk about the first adaption of the RF model to deal with BWM - the COMPLETE CASE APPROACH

	- The idea of the approach is to process the training data such, that it doesn't contain any missing values in 
	  regards to the test-set:
	- To do so:
		- firstly all folds from the training data, that miss a feature-blcok that is available for the test set
	      are removed, as these folds miss features that are availabel for the test data
		- From the remaining folds, the blocks that are not available for the test-data are removed!
			--> Either the resulting data-set is empty, OR 
			    it can be used to train a RF regularly that can provide predicitions for the test data then

	- The figure shows an example for this. 
		- The Test-Set only has the feature-blocks 'Clinical' and 'CNV'
		- After the processing, only the data with the green border can be used to train a RF, that can provide 
		  predictions for the test-set then!

	- This approach has 2 drawbacks:
		> It discards a lot of the available data
		> The processing of the training data can end up in an empty DF, such that the approach can not provide 
		  predicitions then...


7. Slide ----- ----- ----- ----- -----
	>> Lets talk about the second adaption of the RF model to deal with BWM - the SINGLE BLOCK APPROACH

	- The idea of the approach is to only use a single feature-block - that the test & train data have in common - for
	  the training of a RF and create predicitions on the test data then
	- To do so:
		- firstly the feature-blocks the test & train data have in common are extracted. On each of the blocks the test
		  & train data have in common a seperate RF is trained.
		- Each seperate RF can create predicitions for the test data then

	- The figure shows an example for this:
		- The Test-Set only has the feature-blocks 'Clinical' and 'CNV'
		- The from the training data, two processed data sets are created.
		   > one that only consits of the response Y and the Clinical block
		   > one that only consits of the response Y and the CNV block
		- On the processed data, a model can be trained regularly and create predicitons then. 
		  In this example every observation from the test data recieves 2 predicitions (once based on Clinical once on CNV)

	- This approach uses the data not very efficently and can only be applied if test and train data have at least one
	  feature-block in common


8. Slide ----- ----- ----- ----- -----
	>> Lets talk about the thrid adaption of the RF model to deal with BWM - the IMPUTATION APPROACH

	- The idea of the approach is to impute the missing values in the train data, such that the train data is fully 
	  observed afterwards. Then a RF can be trained on the feature-blocks that the train and test data have in common.
	  This model can then provide predicitions for the test-set then.


	- To do so:
		- the missing values are imputed with the 'missForest' method. This method is flexibly applicable, does not
		  require prior knowledge of the data, can handle mixed-type data and is known to perform very well under 
		  barren conditions like high dimensions, complex interactions and non-linear data structures.
		- the feature-blocks that the imputed train data has in common with the test data can be used to fit a RF model
		- This model is fitted regulary and can provide predicitions for the test-set then!

	- The figure shows an example for this:
		- The training data has BWM and the values are imputed with the missforest method
		- Based on the feature-blocks that the test and train data have in common, a usable training set can be created.
		- Based on the usbale trainnig data a RF can be fit regularly and provide predicitons for the test-set!

	- This approach uses the data very efficently and doesn't discard any training features/ observations. 
	- Nevertheless there are 2 big drawbacks of this approach:
	 	[1] Many missing values in the data can lead to unreliable imputations
	 	[2] If the data is a conecation of DFs from diverse sources, the imputation is performmed across multiple 
	 	    heterogenous data sets --> making imputations also unreliable! 


9. Slide ----- ----- ----- ----- -----
	>> Lets talk about the foruth adaption of the RF model to deal with BWM - the Block-Wise APPROACH

	- The idea of this approach is to fit a separate RF on the observed parts of each feature-block. For a predicition
	  on the test data, the predicitions of the block-wise fitted model are aggergated.

	- To do so:
		- a separate RF is fitted regularly on the observed parts of each feature-block 
		- For the prediciton on a test-set, each block-wise fitted RF is asked for a predicition. Only those RFs that 
		  were trained on a block, that is also available for the test-set can create a predicition
		- The block-wise predicitions can then be aggregated in weighted/ unweighted way 

	- The figure shows an example for this:
		- The training data has BWM and a separate RF is fitted on the observed parts of each feature-block
			--> resulting in as many block-wise models as the data has feature-blocks
		- Then for the predicition, only those block-wise models can be used, that were trained on a block that is
		  available for the test data
		  	--> each of these create a separate predicitions
		- The block.wise predicitions can then be aggregated in a weighted/ unweighted way!
			> unweighted: --> Create the plain average of predicted class probabilities
			> weighted:   --> Use the internal OOB-Accuracy/ OOB-F1-Score of the blockwise RFs as weights for a weighted 
			                  average of the predicted class probabilities

	- This approach uses the data very efficently and doesn't discard any training features/ observations. 


10. Slide ----- ----- ----- ----- -----
	>> Lets talk about the foruth adaption of the RF model to deal with BWM - the FOLD-Wise APPROACH

	- The idea of this approach is to fit a separate RF on the observed parts of each feature-block. For a predicition
	  on the test data, the predicitions of the fold-wise fitted model are aggergated then.

	- To do so:
		- Firstly on each fold of the training data, a model is fitted on the observed parts
			- This is displayed in the figure below
		- To predict on the test data, each fold-wise fitted model is asked for a prediciton. 
		   	- Only those models that were fitted on a fold that shares at least on block with the test-set can do so
		   	- It might be that the models must be pruned to create predicitons 
		   	  [this is explanined in more detial on the next slide]
		   	- Then the fold-wise predicitions can be aggregated in a weighted/ unweighted way


11. Slide ----- ----- ----- ----- -----
	>> Let's have a closer look at the 'Pruning' and the predicitons with the fold-wise approach

	- PRUNING:
		- Pruning actually describes a process to avoid overfitting in decision trees. But it can also be applied, if a
		  decision tree contains split-variables that are not available for the test data.
		- e.g. > the decision tree on the left hand side uses the split variables 'height' and 'weight' and three terminal 
		         nodes
		       > It can not be applied to an observation that misses the feature 'height'. 
		       > BUT if we prune the tree at the variable 'height' it can be used for the observation
		       		--> cut off the branch that uses a not available variable and make the node a terminal node!
		       > OBACHT: Trees that need to be pruned at the first split are not usable at all and need to be removed 
		                 completly from the RF!

	- Predicitons:
		- Each fold-wise fitted RF is asked for a prediciton 

			> RF(Hospital2) was fitted on the blocks 'Clinical' & 'RNA'
		        --> Hence this model can create predictions regularly!

		    > RF(Hospital1) was fitted in the blocks 'Clincial' & 'CNV' 
		    	--> Hence the single decision trees of this RF need to be pruned, as they might use a split variable
		    	    that is not availabe for the test-set!

		- The fold-wise predicitions can then be aggrgated in a weighted/ unweighted way!
			> unweighted: --> Create the plain average of predicted class probabilities
			> weighted:   --> Use the internal OOB-Accuracy/ OOB-F1-Score of the pruned RFs as weights for a weighted 
			                  average of the predicted class probabilities

	- This approach uses the data very efficently and doesn't discard any training features/ observations. 

12. Slide ----- ----- ----- ----- -----
	>> Let's have a look on the metrics

	- In general: metrics are used to 'evaluate the performance of a statical learning method - it measures how well the 
	                                   predicitions of the model actually match the observed data'

	- As only datasets with a binary target variable are used to assess the performance of the various approaches, only
	  metric for 'binary classification' are introduced. All of these metrics are insensitive to class imbalances!

	- 'F-1 Score' is the harmonic mean of the precision and the recall [1. = precision || 2. = recall]
	- The 'balanced accuracy' calculates the accuracy per response class and returns the average of these class-wise 
	  accuracies
	- The 'Matthews Correlation Coefficent' can be seen as a discretization of the pearson correlation for binary variables

	--> All metrics have the best value with '1', the 'F-1 Score' and the 'balanced accuracy' have the worst value with 0
	    and the MMC has the worst value with '-1'


13. Slide ----- ----- ----- ----- -----
	>> Let'S talk about the first data source --> 'The Cancer Genome Atlas' - short TCGA

	- In total I recieved 21 processed TCGA datasets from Dr. Hornung, who has used the data in the 'blockForest' article already!
		- The processing included: - the imputation of missing values in the clinical block &  
		                           - the transformation of categorical feature variables to binary numerical variables
		--> !!! 21 fully observed data sets !!!

	- As this thesis compared classification approaches, not the original response variable 'survival-time' was used, but
	  the variable 'gender' from the clincal block 
	   --> This might not be a clinical meaningful outcome, but features major advantages for a methodlogical investigation
	    --> 7 DFs had to be removed, such that 14 usable DFs remained!

	- The 14 DFs all have the same 5 feature-blocks. The dimensions of these were reduced to reduce the computionall effort
	 --> the average amount of variables per feature-block over the 14 TCGA data-sets is shown in the table 
	     - once the original size & once the reduced size
	     		--> Clinical Block has the fewest variables, & RNA the most!


14. Slide ----- ----- ----- ----- -----
	>> As all of the 14 TCGA DFs are fully observed, BWM needs to be induced, such that the various approaches can be 
	   evaluated on this data!

	- In total there are four different patterns:
		- First one shows a case in which each fold is observed in a single omics block + the clinical block
		- The second one the first fold is observed in all 5 blocks, the second fold in four blocks, and so so...
		- For the third pattern, the observed blocks per fold were drawn randomly
		- For the last pattern we mixed up 2 feature-blocks to a single one, whereby each fold is observed in one of
		  these blocks & one additional clinical block!


15. Slide ----- ----- ----- ----- -----
	>> The algorithm shows the procedere to evaluate an approach on the TCGA data

		- Firstly a dataset, and approach and a pattern of BWM have to be choosen
			> The fully observed data is split into 5 equally sized folds for the CV
				> one fold is used as test-set and the remaining 4 as training set!
				> Induce BWM into the train-set according to Pattern
				> Fit the approach on the train-set with BWM
					> Evaluate the fitted model on:
						- fully observed test-set
						- test-set with one missing feature-block
						- test-set with two missing feature-blocks and so on!


16. Slide ----- ----- ----- ----- -----
	>> Let's have a look at the second source of data - the clinical asthama data

		- the data is a real-world data set and was provided by the group of Prof. Dr. med. Bianca Schaub at the 
		  'paediatric clinic Dr. von Haunersches Kinderspital'
		- has a binary target variable that is defined as the presence of asthma
		  from totally 521 observations: 265 have a negative resposne \& 256 have a positive response
		- consits of six feature-blocks:
			- Questionaire, Clinical routine diagnostigs, allergen sensatzion, Cyoktine expression data, gene expression dáta 1&2
		    - amount of observations inversly reflects the effort of generating the data [less obs. more effort!!]


17. Slide ----- ----- ----- ----- -----
	>> Lets briefly introduce the evaluation technique on the clinical asthma data!
		- Firstly the data (with BWM) is split into 5 equally sized folds [éach of these CV-folds has BWM]
		- One of the folds is used as test-set and the remaining 4 folds as train set
		- Then extract the various patterns of BWM in the test-set
		 	- for each pattern of BWM in the test-set, the approach is fitted on the data, such that it can provdide 
		 	  predicitions for the test-set
		 	- After doing this for all patterns of BWM in the test-set, the metric for the current fold can be calculated!


18. Slide ----- ----- ----- ----- ----- 
	>> Now lets talk about the results of the RF based approaches on the TCGA data

	- Firstly the results of the Complete-Case approach are shown.
	- Each row in the figure equals a pattern of Block-Wise missingness in the train data
	- The y-axis shows the F-1 Score and the x.axis the various test-situations
	  (e.g. miss_1A shows the result of the approach, when the test-set misses the first block!)
	 		--> as pattern4 only has 3 instead of 5 blocks, there are less test-situations! 
	 		   --> the test-situations that are not avilabe for pattern 4 are marked with an ornage X

	 	- The first thing that stands out, is that the CC can not always generate predicitons - e.g. pattern 1 - full
	 		--> this is meaningful, as the CC can only provide predictions, when the train-set contains Complete-Cases 
	 		    regarding the current test-set!
	 	- Else it can be seen, that the perfromance highly depends on the availabe feature-blocks in the test-set
	 	  (e.g. Pattern1 single_A & single_B)


19. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Single-Block approach are shown.
	- For each pattern of BWM the results are shown split by the block that was used for the training of the SB-Approach
	- Two things are standing out:
		- Firstly: The SB approach can only generate predicitons for the test-sets that contain the block, that has been initially used for the training
		           (e.g. pattern4 - 'A' can only provide predicitons for test-sets with 'A')
		- Secondly: The performance of a single-block model is the same for the various test-situations. This makes 
		            sense, as the SB approach only uses a single block for the predicition & the various test-situations
		            only differ in the observed blocks, BUT not the blocks itself!


20. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Imputation approach are shown.
	- It stands out, that the imputation approach can provide predicitons for all possible test-situations!


21. Slide ----- ----- ----- ----- ----- 
	- Next the results of the Block-Wise approach are shown.
	- To each test-situation, the results are shown structured by the weight used to aggregate the predicitions
	- It stands out, that the BW approach can provide predicitons for all possible test-situations!
	- Furthermore, it can be seen, that the weight_metric has no influence in the test-situations 'single_A'-'single_CL'
		--> this makes sense, as the test-set only consits of a single block 
		   --> no aggregation of BW predicitons!
	- Else it can be seen, that in all patterns and almost all test-situations the performance of the BW approach is the
	  best with the 'F-1 Score' as weight metric!


22. Slide ----- ----- ----- ----- -----
	- Last but not least the results of the FW approach are shown
	- As the BW & Imputation approach, this approach can provide predicitons for each test-situation
	- Furthermore, it can be seen, that the weight_metric has no influence in the test-situations in which only a single
	  fold from the training data can be used 
	  	- e.g. with 'Pattern 1' the performance in the test-situations 'single A', 'single B', 'single C' and
              'single D' is equal for the different weight metrics. 
              	--> That is reasonable, as in these test-situations only a single fold-wise fitted random forest model can
                    provide predictions, as the training-set only has a single fold that can be used for these test-situations.
					--> no aggregation of FW predicitons!

23. Slide ----- ----- ----- ----- -----